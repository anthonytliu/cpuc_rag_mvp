#!/usr/bin/env python3
# Verify that optimizations are properly configured

import logging
import os
import config
from data_processing import doc_converter

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def verify_optimizations():
    """Verify that all optimizations are properly configured"""
    
    logger.info("üîç Verifying optimization configurations...")
    logger.info("="*50)
    
    # Check config settings
    logger.info("üìã Configuration Settings:")
    logger.info(f"  URL_PARALLEL_WORKERS: {getattr(config, 'URL_PARALLEL_WORKERS', 'NOT SET')}")
    logger.info(f"  VECTOR_STORE_BATCH_SIZE: {getattr(config, 'VECTOR_STORE_BATCH_SIZE', 'NOT SET')}")
    logger.info(f"  DOCLING_FAST_MODE: {getattr(config, 'DOCLING_FAST_MODE', 'NOT SET')}")
    logger.info(f"  DOCLING_THREADS: {getattr(config, 'DOCLING_THREADS', 'NOT SET')}")
    logger.info(f"  EMBEDDING_BATCH_SIZE: {getattr(config, 'EMBEDDING_BATCH_SIZE', 'NOT SET')}")
    
    # Check environment variables
    logger.info("\nüåç Environment Variables:")
    logger.info(f"  OMP_NUM_THREADS: {os.environ.get('OMP_NUM_THREADS', 'NOT SET')}")
    
    # Verify Docling configuration
    logger.info("\n‚öôÔ∏è  Docling Configuration:")
    try:
        # Check if fast mode is enabled
        pipeline_options = doc_converter.format_options[config.InputFormat.PDF].pipeline_options
        table_mode = pipeline_options.table_structure_options.mode
        logger.info(f"  Table processing mode: {table_mode}")
        
        if hasattr(pipeline_options, 'page_boundary'):
            logger.info(f"  Page boundary: {pipeline_options.page_boundary}")
        else:
            logger.info("  Page boundary: Not set (no limit)")
            
    except Exception as e:
        logger.warning(f"  Could not verify Docling config: {e}")
    
    # Performance expectations
    logger.info("\nüéØ Expected Performance Improvements:")
    logger.info("  ‚Ä¢ Parallel processing: 2-3x for multiple URLs")
    logger.info("  ‚Ä¢ Fast table mode: 10-20% Docling speedup") 
    logger.info("  ‚Ä¢ Larger batches: 50% vector store speedup")
    logger.info("  ‚Ä¢ Overall target: 20-40% total improvement")
    
    # Recommendations
    logger.info("\nüí° Optimization Status:")
    
    checks = []
    
    # Check parallel workers
    if hasattr(config, 'URL_PARALLEL_WORKERS') and config.URL_PARALLEL_WORKERS > 1:
        checks.append("‚úÖ Parallel URL processing enabled")
    else:
        checks.append("‚ùå Parallel URL processing not configured")
    
    # Check batch size
    if hasattr(config, 'VECTOR_STORE_BATCH_SIZE') and config.VECTOR_STORE_BATCH_SIZE > 64:
        checks.append("‚úÖ Optimized vector store batch size")
    else:
        checks.append("‚ùå Vector store batch size not optimized")
        
    # Check fast mode
    if hasattr(config, 'DOCLING_FAST_MODE') and config.DOCLING_FAST_MODE:
        checks.append("‚úÖ Docling fast mode enabled")
    else:
        checks.append("‚ùå Docling fast mode not enabled")
        
    # Check threading
    if os.environ.get('OMP_NUM_THREADS'):
        checks.append("‚úÖ Docling threading configured")
    else:
        checks.append("‚ùå Docling threading not configured")
    
    for check in checks:
        logger.info(f"  {check}")
    
    success_count = sum(1 for check in checks if check.startswith("‚úÖ"))
    total_count = len(checks)
    
    logger.info(f"\nüìä Optimization Score: {success_count}/{total_count} ({success_count/total_count*100:.0f}%)")
    
    if success_count == total_count:
        logger.info("üéâ All optimizations are properly configured!")
        return True
    else:
        logger.warning("‚ö†Ô∏è  Some optimizations may not be active")
        return False

if __name__ == "__main__":
    verify_optimizations()
    
    logger.info("\nüìà To test performance improvements:")
    logger.info("  python test_performance_optimization.py")
    logger.info("  python test_parallel_benefits.py")